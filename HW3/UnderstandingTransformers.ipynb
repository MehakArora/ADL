{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79460fbd-9422-4963-8448-4acc6875ae44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youre very clever</td>\n",
       "      <td>[start] vous etes fort ingenieuse [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>are there kids</td>\n",
       "      <td>[start] y atil des enfants  [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>come in</td>\n",
       "      <td>[start] entrez [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wheres boston</td>\n",
       "      <td>[start] ou est boston [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you see what i mean</td>\n",
       "      <td>[start] vous voyez ce que je veux dire  [end]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    en                                             fr\n",
       "0    youre very clever        [start] vous etes fort ingenieuse [end]\n",
       "1       are there kids              [start] y atil des enfants  [end]\n",
       "2              come in                           [start] entrez [end]\n",
       "3        wheres boston                    [start] ou est boston [end]\n",
       "4  you see what i mean  [start] vous voyez ce que je veux dire  [end]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Clean the text by removing punctuation symbols and numbers, converting\n",
    "characters to lowercase, and replacing Unicode characters with their ASCII\n",
    "equivalents. For the French samples, insert [start] and [end] tokens at the\n",
    " beginning and end of each phrase\"\"\"\n",
    "import pandas as pd\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "df = pd.read_csv('Data/en-fr.txt', names=['en', 'fr', 'attr'], usecols=['en', 'fr'], sep='\\t')\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = normalize('NFD', text.lower())\n",
    "    text = re.sub('[^A-Za-z ]+', '', text)\n",
    "    return text\n",
    "\n",
    "def clean_and_prepare_text(text):\n",
    "    text = '[start] ' + clean_text(text) + ' [end]'\n",
    "    return text\n",
    "\n",
    "df['en'] = df['en'].apply(lambda row: clean_text(row))\n",
    "df['fr'] = df['fr'].apply(lambda row: clean_and_prepare_text(row))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2bb344-f169-4444-9449-bfe4945091b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max phrase length (English): 7\n",
      "Max phrase length (French): 16\n",
      "Sequence length: 16\n"
     ]
    }
   ],
   "source": [
    "\"\"\"The next step is to scan the phrases and determine the maximum length of the\n",
    "English phrases and then of the French phrases. These lengths will determine\n",
    "the lengths of the sequences input to and output from the model\"\"\"\n",
    "en = df['en']\n",
    "fr = df['fr']\n",
    "\n",
    "en_max_len = max(len(line.split()) for line in en)\n",
    "fr_max_len = max(len(line.split()) for line in fr)\n",
    "sequence_len = max(en_max_len, fr_max_len)\n",
    "\n",
    "print(f'Max phrase length (English): {en_max_len}')\n",
    "print(f'Max phrase length (French): {fr_max_len}')\n",
    "print(f'Sequence length: {sequence_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53810316-cdfb-449d-b13e-8fa65e077fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchnlp.encoders.text import TreebankEncoder\n",
    "from torchnlp.encoders.text import pad_tensor, stack_and_pad_tensors\n",
    "from torchnlp.encoders.text import StaticTokenizerEncoder\n",
    "\n",
    "def french_tokenize(text):\n",
    "    text = text.replace('!', ' ').replace('\"', ' ').replace('#', ' ') \\\n",
    "            .replace('$', ' ').replace('%', ' ').replace('&', ' ') \\\n",
    "            .replace('(', ' ').replace(')', ' ').replace('*', ' ') \\\n",
    "            .replace('+', ' ').replace(',', ' ').replace('-', ' ') \\\n",
    "            .replace('.', ' ').replace('/', ' ').replace(':', ' ') \\\n",
    "            .replace(';', ' ').replace('<', ' ').replace('=', ' ') \\\n",
    "            .replace('>', ' ').replace('?', ' ').replace('@', ' ') \\\n",
    "            .replace('\\\\', ' ').replace('^', ' ').replace('_', ' ') \\\n",
    "            .replace('`', ' ').replace('{', ' ').replace('|', ' ') \\\n",
    "            .replace('}', ' ').replace('~', ' ').replace('\\t', ' ') \\\n",
    "            .replace('\\n', ' ')\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def custom_pad_sequences(sequences, max_len, padding_value=0):\n",
    "    padded_seqs = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < max_len:\n",
    "            # Pad the sequence\n",
    "            padded = torch.cat([seq, torch.tensor([padding_value] * (max_len - len(seq)), dtype=torch.long)])\n",
    "        else:\n",
    "            # Truncate if longer than max_len\n",
    "            padded = seq[:max_len]\n",
    "        padded_seqs.append(padded)\n",
    "    return torch.stack(padded_seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6b0014-5724-4ba6-98b7-6b7b53c2f71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /hpc/home/ma618/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /hpc/home/ma618/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "entokenizer = TreebankEncoder(en)\n",
    "frtokenizer = StaticTokenizerEncoder(fr, tokenize=french_tokenize, append_eos=False, reserved_tokens=['<pad>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84e908a1-88bf-40d7-945b-fc324e6c5773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2770205/1891977763.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  en_sequences = [torch.tensor(entokenizer.encode(sentence)) for sentence in en]\n",
      "/tmp/ipykernel_2770205/1891977763.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fr_sequences = [torch.tensor(frtokenizer.encode(sentence)) for sentence in fr]\n"
     ]
    }
   ],
   "source": [
    "en_sequences = [torch.tensor(entokenizer.encode(sentence)) for sentence in en]\n",
    "fr_sequences = [torch.tensor(frtokenizer.encode(sentence)) for sentence in fr]\n",
    "\n",
    "# Pad the sequences to the desired length\n",
    "en_x = custom_pad_sequences(en_sequences, sequence_len, padding_value=0)\n",
    "fr_y = custom_pad_sequences(fr_sequences, sequence_len + 1, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0a7528-d1f3-4532-927a-f7f183436905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size (English): 6038\n",
      "Vocabulary size (French): 12198\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Compute the vocabulary sizes from the Tokenizer instances\"\"\"\n",
    "en_vocab_size = len(entokenizer.vocab) + 1\n",
    "fr_vocab_size = len(frtokenizer.vocab) + 1\n",
    "\n",
    "print(f'Vocabulary size (English): {en_vocab_size}')\n",
    "print(f'Vocabulary size (French): {fr_vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0588cb87-b980-4fcb-b23f-2fb32c8e2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Finally, create the features and the labels the model will be trained with.\n",
    "The features are the padded English sequences and the padded French sequences\n",
    "minus the [end] tokens. The labels are the padded French sequences minus the\n",
    "[start] tokens. Package the features in a dictionary so they can be input to a\n",
    "model that accepts multiple inputs.\"\"\"\n",
    "inputs = { 'encoder_input': en_x, 'decoder_input': fr_y[:, :-1] }\n",
    "outputs = fr_y[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82c4ebbc-173c-40de-8ebc-8f5614206b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import transformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56252e81-be27-488b-99ce-45a7908ae85c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
